{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Structural Topic Modelling for NHS survey data","text":"<p>This model is not currently suitable for predicting patient non-attendance in a real-world healthcare environment.</p> <p>Note: All example data used in this repository is simulated and for illustrative purposes only.  The dataset used in the analysis is provided. It is originally from Nottinghamshire Healthcare NHS Foundation Trust's CDU Data Science Team</p> <p>See code <code>README</code> for installation and usage instructions. </p>"},{"location":"#overview","title":"Overview","text":"<p>A reusable codebase with example data for applying structural topic modelling (STM) to survey data. This technique allows contextual information (e.g. question number) to be included in the topic allocation.  </p> <p>The codebase includes example preprocessing of data, NGram analysis, sentiment analysis and the actual structural topic modelling.  Additionally, there is a text search function enabled using WordNet.   </p> <p>To visualise and interpret the topic models we examined the range of outputs in the stm R package, such as word clouds, plot the estimated effect of the metadata, and print most associated words. ToLDAvis was used to visualise the topic-word distributions in an interactive pop-out window. This provided an overview of topic quality by looking at topic content and similarity. stminsights package was used to produced an interactive dashboard for a detailed inspection of the model and topics.</p> <p> </p> <p> Figure 1: Example Screenshot from STM insights</p>"},{"location":"contact/","title":"Contact","text":"<p>This work was undertaken by during early 2022 by colleagues within the digital analysis and research team (DART) in the Transformation Directorate of NHS England.</p> <p>See our other open projects here or get in contact by emailing datascience@nhs.net</p>"},{"location":"preprocessing/","title":"Preprocessing and Text Analysis","text":""},{"location":"preprocessing/#preprocessing","title":"Preprocessing","text":"<p>The data were cleaned to remove rows with null values and declare the data types of each variable, a process dependent on the dataset. The responses were prepared for topic modelling by expanding contractions (e.g., don\u2019t -\u00bf do not) , removing punctuation and digits, making words lowercase and removing stopwords. Stopwords are words which convey little to no additional meaning to a sentence such as \u201da\u201d \u201dand\u201d \u201dam\u201d. These stop words are able to be customised to include other non-informative words from the corpus as determined by the user such as \u201dnothing\u201d and \u201dnope\u201d. The words were also normalised to their root using stemming or lemmatisation, tokenised and converted into a document feature matrix for STM. All tokens are unigrams, unless otherwise stated. Responses that had fewer than 3 tokens were removed. In stemming a part of the word is removed to reduce the word it stem. In lemmatisation, a word is mapped to its lemma, or canonical form. Lemmatisation can been seen as more interpretable as the root derived are real words and words such as \u201dhappy\u201d and \u201dhappily\u201d map to \u201dhappy\u201d where as with stemming they would map to \u201dhappy\u201d and \u201dhappi\u201d. \u201drun\u201d, \u201drunning\u201d and \u201dran\u201d all map to \u201drun\u201d .</p>"},{"location":"preprocessing/#n-gram-analysis","title":"N-gram analysis","text":"<p>The Tidytext library was used to extract unigrams, bigrams and trigrams from the text.The frequency of these n-grams was calculated, which provided an overview of the types of words and phrases in the data. This was used to highlight features that needed to be considered in the preprocessing. Unigrams and bigrams were used as the input for stm in an experiment. Otherwise, only unigrams were used.</p>"},{"location":"preprocessing/#sentiment-analysis","title":"Sentiment Analysis","text":"<p>Sentiment analysis calculates the affective state of text. Commonly, polarity is calculated, in which a score is given stating how positive, negative or neutral a statement is. Several sentiment analysis tools available in R perform well on text. On the raw data, we compared the performance of VADER, SentimentAnalysis, ANew and NRC emotion lexicon. The libraries operate using different methods and are trained with different corpora, for example, VADER is a rule based dictionary trained on Twitter data and SentimentAnalysis: Dictionary GI is a general purpose dictionary using Havard-IV dictionary.</p>"},{"location":"stm/","title":"Structural Topic Modelling","text":"<p>Topic modelling and word clustering are common natural language processing (NLP) approaches to obtaining insight into text. They have been used to facilitate qualitative text analysis through automating topic extraction, and grouping semantically similar text.  Structural topic models (STM) are a generative models that are an extension of topic models such as Latent Dirichlet Allocation (LDA) and Correlated Topic Model (CTM). These models identify latent topics in text. A topic is a set of words where each word has a probability of belonging to that topic. A document is a mixture of topics that can also be correlated.</p> <p>Unlike LDA and CTM, STM enables the covariates (metadata) to be associated with a document of interest. The metadata covariates may influence the topic mentioned or during data generation, such as the date or trust the survey is collected. For example, feedback during the winter may include details about longer wait times and demand on services. Essentially, STM enables context to be added when generating a topic model. </p> <p>In general, the model iterates through each word in a document. Based on a prior distribution of the topic proportions, the model assigns the word to a topic. The metadata covariates can influence the prevalence of the topics. In this way, documents with similar covariates will tend to mention similar topics and use more similar words to discuss them. The value of STM lies in its ability to discover topics in a corpus and estimate the effect of the associated metadata. The analyst is then able to look at the relationship between variables and topics in the text, which enables model interpretability and hypothesis testing. Some applications of STM have included examining the public opinion of the UK government throughout the COVID-19 pandemic; understanding causes of user dissatisfaction from complaints and topics present in aviation incident reports. STM has also been used alongside other text analytic methods such as sentiment predictions and hierarchical clustering to improve the usability of Intelligent Personal Assistants.</p> <p>STM was implemented using stm R package. searchK is used alongside Semantic coherence, exclusivity score, heldout log-likelihood and lower bound are used to determine the number of topics (K) for the model. </p> <p>The best performing models are evaluated qualitatively by manually looking at representative text (higher proportion of text estimated for a given topic) and the most associated words, such as words ranked highest by FREX score and those with the highest probability. FREX score is a weighted mean of the probability of a word appearing in a topic (frequency) and its exclusivity to a topic.  </p>"}]}